{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy as cvx\n",
    "from scipy.stats import norm\n",
    "from numpy.linalg import inv\n",
    "import math\n",
    "\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for plotting\n",
    "import plotly\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize plotly offline\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_stocks = ['SPY', # The SP500 as a benchmark\n",
    "             'AAPL', 'MMM', 'BA' , 'CAT', 'CVX' , 'CSCO', 'KO' , 'DIS',\n",
    "             'GS', 'IBM', 'INTC', 'JNJ', 'JPM', 'MSFT', 'PFE'] #Some stocks from the Dow Jones\n",
    "\n",
    "start_data = '2008-09-01'\n",
    "end_date = '2008-10-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_stock_data(start_data, end_date, us_stocks, 'us_stocks_latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data again\n",
    "us_stock_prices = pd.read_csv('./00_Data/us_stocks_latest.csv', header=0, index_col = 0)\n",
    "us_stock_prices.index = pd.to_datetime(us_stock_prices.index)\n",
    "\n",
    "#Process Stock Data\n",
    "stock_prices_norm, stock_returns = process_stock_data(us_stock_prices)\n",
    "\n",
    "# Extract benchmark SP500 Data\n",
    "SPY_benchmark = stock_prices_norm.drop(us_stocks[1:], axis=1)\n",
    "us_stock_prices_norm_wo_SPY = stock_prices_norm.drop(us_stocks[0], axis=1)\n",
    "\n",
    "# filter out benchmark data from stock returns\n",
    "us_stock_returns = stock_returns.drop(us_stocks[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hundred stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data again\n",
    "hundred_stock_prices = pd.read_csv('./00_Data/hundred_stocks.csv', header=0, index_col = 0)\n",
    "hundred_stock_prices.index = pd.to_datetime(hundred_stock_prices.index)\n",
    "\n",
    "#Process Stock Data\n",
    "hundred_stock_prices_norm, hundred_stock_returns = process_stock_data(hundred_stock_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select subprime mortgage crisis data from hundred stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprime_mortgage_crisis = hundred_stock_prices.loc['2008-09'].dropna(axis=1) \n",
    "SMPC_returns = process_stock_data(subprime_mortgage_crisis)[1] # H_i,t of each asset i for t = 1,...,20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directions: Deep portfolio using neural network\n",
    "\n",
    "Next we are to implement the deep portfolio. Recall the four step procedure: \n",
    "- **Auto-encoding**: this phase is essentially dimension reduction. *In the paper: one hidden layer with five neurons*.\n",
    "- **Calibration**: using the stock price of the first few years, our target index $Y$ is the S&P500 (we can also play with this target so that the portfolio map can possibly outperform S&P500 -- but this is for later). *In the paper: ReLU and 4-fold cross validation*. \n",
    "- **Validation**: out-sample validation. Will need to test with different number of stocks.\n",
    "- **Verification**: deep frontier. We look at the 2-norm out-of-sample error for different number of stocks used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Auto-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import `Sequential` from `keras.models`\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "opt = RMSprop(lr=0.001)\n",
    "\n",
    "# Import `Dense` from `keras.layers`\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "#input 87 stock data, and the hidden layer has 5 neurons; no biased involved (unless we let use_bias = TRUE)\n",
    "model.add(Dense(units = 5, input_dim = 87, activation='relu', kernel_initializer = 'he_normal', use_bias = False))\n",
    "model.add(Dense(units = 87, activation='relu', use_bias = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set optimizer and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = RMSprop(lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile & Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "20/20 [==============================] - 0s 6ms/step - loss: 0.4100 - mean_absolute_error: 0.4336\n",
      "Epoch 2/200\n",
      "20/20 [==============================] - 0s 66us/step - loss: 0.4236 - mean_absolute_error: 0.4820\n",
      "Epoch 3/200\n",
      "20/20 [==============================] - 0s 55us/step - loss: 0.4099 - mean_absolute_error: 0.4330\n",
      "Epoch 4/200\n",
      "20/20 [==============================] - 0s 58us/step - loss: 0.4095 - mean_absolute_error: 0.4297\n",
      "Epoch 5/200\n",
      "20/20 [==============================] - 0s 48us/step - loss: 0.4095 - mean_absolute_error: 0.4290\n",
      "Epoch 6/200\n",
      "20/20 [==============================] - 0s 44us/step - loss: 0.4095 - mean_absolute_error: 0.4288\n",
      "Epoch 7/200\n",
      "20/20 [==============================] - 0s 54us/step - loss: 0.4095 - mean_absolute_error: 0.4287\n",
      "Epoch 8/200\n",
      "20/20 [==============================] - 0s 52us/step - loss: 0.4095 - mean_absolute_error: 0.4287\n",
      "Epoch 9/200\n",
      "20/20 [==============================] - 0s 53us/step - loss: 0.4095 - mean_absolute_error: 0.4286\n",
      "Epoch 10/200\n",
      "20/20 [==============================] - 0s 61us/step - loss: 0.4094 - mean_absolute_error: 0.4285\n",
      "Epoch 11/200\n",
      "20/20 [==============================] - 0s 74us/step - loss: 0.4094 - mean_absolute_error: 0.4286\n",
      "Epoch 12/200\n",
      "20/20 [==============================] - 0s 55us/step - loss: 0.4095 - mean_absolute_error: 0.4287\n",
      "Epoch 13/200\n",
      "20/20 [==============================] - 0s 60us/step - loss: 0.4095 - mean_absolute_error: 0.4299\n",
      "Epoch 14/200\n",
      "20/20 [==============================] - 0s 48us/step - loss: 0.4096 - mean_absolute_error: 0.4302\n",
      "Epoch 15/200\n",
      "20/20 [==============================] - 0s 55us/step - loss: 0.4098 - mean_absolute_error: 0.4332\n",
      "Epoch 16/200\n",
      "20/20 [==============================] - 0s 50us/step - loss: 0.4100 - mean_absolute_error: 0.4336\n",
      "Epoch 17/200\n",
      "20/20 [==============================] - 0s 54us/step - loss: 0.4103 - mean_absolute_error: 0.4367\n",
      "Epoch 18/200\n",
      "20/20 [==============================] - 0s 54us/step - loss: 0.4104 - mean_absolute_error: 0.4365\n",
      "Epoch 19/200\n",
      "20/20 [==============================] - 0s 58us/step - loss: 0.4104 - mean_absolute_error: 0.4375\n",
      "Epoch 20/200\n",
      "20/20 [==============================] - 0s 50us/step - loss: 0.4101 - mean_absolute_error: 0.4349\n",
      "Epoch 21/200\n",
      "20/20 [==============================] - 0s 51us/step - loss: 0.4099 - mean_absolute_error: 0.4340\n",
      "Epoch 22/200\n",
      "20/20 [==============================] - 0s 59us/step - loss: 0.4098 - mean_absolute_error: 0.4325\n",
      "Epoch 23/200\n",
      "20/20 [==============================] - 0s 59us/step - loss: 0.4097 - mean_absolute_error: 0.4326\n",
      "Epoch 24/200\n",
      "20/20 [==============================] - 0s 79us/step - loss: 0.4097 - mean_absolute_error: 0.4318\n",
      "Epoch 25/200\n",
      "20/20 [==============================] - 0s 82us/step - loss: 0.4097 - mean_absolute_error: 0.4326\n",
      "Epoch 26/200\n",
      "20/20 [==============================] - 0s 59us/step - loss: 0.4098 - mean_absolute_error: 0.4323\n",
      "Epoch 27/200\n",
      "20/20 [==============================] - 0s 51us/step - loss: 0.4099 - mean_absolute_error: 0.4341\n",
      "Epoch 28/200\n",
      "20/20 [==============================] - 0s 64us/step - loss: 0.4100 - mean_absolute_error: 0.4340\n",
      "Epoch 29/200\n",
      "20/20 [==============================] - 0s 54us/step - loss: 0.4102 - mean_absolute_error: 0.4358\n",
      "Epoch 30/200\n",
      "20/20 [==============================] - 0s 64us/step - loss: 0.4101 - mean_absolute_error: 0.4350\n",
      "Epoch 31/200\n",
      "20/20 [==============================] - 0s 49us/step - loss: 0.4101 - mean_absolute_error: 0.4356\n",
      "Epoch 32/200\n",
      "20/20 [==============================] - 0s 50us/step - loss: 0.4100 - mean_absolute_error: 0.4341\n",
      "Epoch 33/200\n",
      "20/20 [==============================] - 0s 49us/step - loss: 0.4099 - mean_absolute_error: 0.4342\n",
      "Epoch 34/200\n",
      "20/20 [==============================] - 0s 82us/step - loss: 0.4098 - mean_absolute_error: 0.4329\n",
      "Epoch 35/200\n",
      "20/20 [==============================] - 0s 93us/step - loss: 0.4098 - mean_absolute_error: 0.4333\n",
      "Epoch 36/200\n",
      "20/20 [==============================] - 0s 65us/step - loss: 0.4098 - mean_absolute_error: 0.4324\n",
      "Epoch 37/200\n",
      "20/20 [==============================] - 0s 51us/step - loss: 0.4098 - mean_absolute_error: 0.4332\n",
      "Epoch 38/200\n",
      "20/20 [==============================] - 0s 48us/step - loss: 0.4098 - mean_absolute_error: 0.4327\n",
      "Epoch 39/200\n",
      "20/20 [==============================] - 0s 46us/step - loss: 0.4099 - mean_absolute_error: 0.4342\n",
      "Epoch 40/200\n",
      "20/20 [==============================] - 0s 48us/step - loss: 0.4100 - mean_absolute_error: 0.4338\n",
      "Epoch 41/200\n",
      "20/20 [==============================] - 0s 44us/step - loss: 0.4101 - mean_absolute_error: 0.4352\n",
      "Epoch 42/200\n",
      "20/20 [==============================] - 0s 54us/step - loss: 0.4101 - mean_absolute_error: 0.4345\n",
      "Epoch 43/200\n",
      "20/20 [==============================] - 0s 67us/step - loss: 0.4101 - mean_absolute_error: 0.4350\n",
      "Epoch 44/200\n",
      "20/20 [==============================] - 0s 66us/step - loss: 0.4100 - mean_absolute_error: 0.4338\n",
      "Epoch 45/200\n",
      "20/20 [==============================] - 0s 64us/step - loss: 0.4099 - mean_absolute_error: 0.4340\n",
      "Epoch 46/200\n",
      "20/20 [==============================] - 0s 57us/step - loss: 0.4099 - mean_absolute_error: 0.4330\n",
      "Epoch 47/200\n",
      "20/20 [==============================] - 0s 65us/step - loss: 0.4098 - mean_absolute_error: 0.4334\n",
      "Epoch 48/200\n",
      "20/20 [==============================] - 0s 65us/step - loss: 0.4098 - mean_absolute_error: 0.4327\n",
      "Epoch 49/200\n",
      "20/20 [==============================] - 0s 69us/step - loss: 0.4099 - mean_absolute_error: 0.4337\n",
      "Epoch 50/200\n",
      "20/20 [==============================] - 0s 59us/step - loss: 0.4099 - mean_absolute_error: 0.4331\n",
      "Epoch 51/200\n",
      "20/20 [==============================] - 0s 47us/step - loss: 0.4099 - mean_absolute_error: 0.4343\n",
      "Epoch 52/200\n",
      "20/20 [==============================] - 0s 42us/step - loss: 0.4099 - mean_absolute_error: 0.4337\n",
      "Epoch 53/200\n",
      "20/20 [==============================] - 0s 42us/step - loss: 0.4100 - mean_absolute_error: 0.4347\n",
      "Epoch 54/200\n",
      "20/20 [==============================] - 0s 48us/step - loss: 0.4100 - mean_absolute_error: 0.4340\n",
      "Epoch 55/200\n",
      "20/20 [==============================] - 0s 45us/step - loss: 0.4100 - mean_absolute_error: 0.4346\n",
      "Epoch 56/200\n",
      "20/20 [==============================] - 0s 55us/step - loss: 0.4100 - mean_absolute_error: 0.4338\n",
      "Epoch 57/200\n",
      "20/20 [==============================] - 0s 44us/step - loss: 0.4099 - mean_absolute_error: 0.4340\n",
      "Epoch 58/200\n",
      "20/20 [==============================] - 0s 43us/step - loss: 0.4099 - mean_absolute_error: 0.4330\n",
      "Epoch 59/200\n",
      "20/20 [==============================] - 0s 37us/step - loss: 0.4099 - mean_absolute_error: 0.4335\n",
      "Epoch 60/200\n",
      "20/20 [==============================] - 0s 57us/step - loss: 0.4098 - mean_absolute_error: 0.4328\n",
      "Epoch 61/200\n",
      "20/20 [==============================] - 0s 57us/step - loss: 0.4099 - mean_absolute_error: 0.4337\n",
      "Epoch 62/200\n",
      "20/20 [==============================] - 0s 54us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 63/200\n",
      "20/20 [==============================] - 0s 49us/step - loss: 0.4099 - mean_absolute_error: 0.4342\n",
      "Epoch 64/200\n",
      "20/20 [==============================] - 0s 47us/step - loss: 0.4099 - mean_absolute_error: 0.4337\n",
      "Epoch 65/200\n",
      "20/20 [==============================] - 0s 43us/step - loss: 0.4100 - mean_absolute_error: 0.4346\n",
      "Epoch 66/200\n",
      "20/20 [==============================] - 0s 44us/step - loss: 0.4100 - mean_absolute_error: 0.4338\n",
      "Epoch 67/200\n",
      "20/20 [==============================] - 0s 49us/step - loss: 0.4100 - mean_absolute_error: 0.4344\n",
      "Epoch 68/200\n",
      "20/20 [==============================] - 0s 74us/step - loss: 0.4099 - mean_absolute_error: 0.4335\n",
      "Epoch 69/200\n",
      "20/20 [==============================] - 0s 79us/step - loss: 0.4099 - mean_absolute_error: 0.4341\n",
      "Epoch 70/200\n",
      "20/20 [==============================] - 0s 53us/step - loss: 0.4099 - mean_absolute_error: 0.4333\n",
      "Epoch 71/200\n",
      "20/20 [==============================] - 0s 60us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 72/200\n",
      "20/20 [==============================] - 0s 50us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 73/200\n",
      "20/20 [==============================] - 0s 49us/step - loss: 0.4099 - mean_absolute_error: 0.4339\n",
      "Epoch 74/200\n",
      "20/20 [==============================] - 0s 43us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "20/20 [==============================] - 0s 62us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 76/200\n",
      "20/20 [==============================] - 0s 62us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 77/200\n",
      "20/20 [==============================] - 0s 54us/step - loss: 0.4099 - mean_absolute_error: 0.4341\n",
      "Epoch 78/200\n",
      "20/20 [==============================] - 0s 52us/step - loss: 0.4099 - mean_absolute_error: 0.4334\n",
      "Epoch 79/200\n",
      "20/20 [==============================] - 0s 55us/step - loss: 0.4099 - mean_absolute_error: 0.4341\n",
      "Epoch 80/200\n",
      "20/20 [==============================] - 0s 63us/step - loss: 0.4099 - mean_absolute_error: 0.4334\n",
      "Epoch 81/200\n",
      "20/20 [==============================] - 0s 63us/step - loss: 0.4099 - mean_absolute_error: 0.4343\n",
      "Epoch 82/200\n",
      "20/20 [==============================] - 0s 39us/step - loss: 0.4099 - mean_absolute_error: 0.4335\n",
      "Epoch 83/200\n",
      "20/20 [==============================] - 0s 46us/step - loss: 0.4099 - mean_absolute_error: 0.4341\n",
      "Epoch 84/200\n",
      "20/20 [==============================] - 0s 37us/step - loss: 0.4099 - mean_absolute_error: 0.4333\n",
      "Epoch 85/200\n",
      "20/20 [==============================] - 0s 41us/step - loss: 0.4099 - mean_absolute_error: 0.4341\n",
      "Epoch 86/200\n",
      "20/20 [==============================] - 0s 39us/step - loss: 0.4099 - mean_absolute_error: 0.4333\n",
      "Epoch 87/200\n",
      "20/20 [==============================] - 0s 44us/step - loss: 0.4099 - mean_absolute_error: 0.4339\n",
      "Epoch 88/200\n",
      "20/20 [==============================] - 0s 43us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 89/200\n",
      "20/20 [==============================] - 0s 42us/step - loss: 0.4099 - mean_absolute_error: 0.4340\n",
      "Epoch 90/200\n",
      "20/20 [==============================] - 0s 52us/step - loss: 0.4099 - mean_absolute_error: 0.4334\n",
      "Epoch 91/200\n",
      "20/20 [==============================] - 0s 46us/step - loss: 0.4099 - mean_absolute_error: 0.4339\n",
      "Epoch 92/200\n",
      "20/20 [==============================] - 0s 46us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 93/200\n",
      "20/20 [==============================] - 0s 42us/step - loss: 0.4099 - mean_absolute_error: 0.4339\n",
      "Epoch 94/200\n",
      "20/20 [==============================] - 0s 47us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 95/200\n",
      "20/20 [==============================] - 0s 51us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 96/200\n",
      "20/20 [==============================] - 0s 48us/step - loss: 0.4099 - mean_absolute_error: 0.4331\n",
      "Epoch 97/200\n",
      "20/20 [==============================] - 0s 60us/step - loss: 0.4099 - mean_absolute_error: 0.4340\n",
      "Epoch 98/200\n",
      "20/20 [==============================] - 0s 55us/step - loss: 0.4099 - mean_absolute_error: 0.4333\n",
      "Epoch 99/200\n",
      "20/20 [==============================] - 0s 56us/step - loss: 0.4099 - mean_absolute_error: 0.4340\n",
      "Epoch 100/200\n",
      "20/20 [==============================] - 0s 91us/step - loss: 0.4099 - mean_absolute_error: 0.4334\n",
      "Epoch 101/200\n",
      "20/20 [==============================] - 0s 75us/step - loss: 0.4099 - mean_absolute_error: 0.4342\n",
      "Epoch 102/200\n",
      "20/20 [==============================] - 0s 57us/step - loss: 0.4099 - mean_absolute_error: 0.4334\n",
      "Epoch 103/200\n",
      "20/20 [==============================] - 0s 55us/step - loss: 0.4099 - mean_absolute_error: 0.4340\n",
      "Epoch 104/200\n",
      "20/20 [==============================] - 0s 56us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 105/200\n",
      "20/20 [==============================] - 0s 72us/step - loss: 0.4099 - mean_absolute_error: 0.4340\n",
      "Epoch 106/200\n",
      "20/20 [==============================] - 0s 68us/step - loss: 0.4099 - mean_absolute_error: 0.4333\n",
      "Epoch 107/200\n",
      "20/20 [==============================] - 0s 68us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 108/200\n",
      "20/20 [==============================] - 0s 65us/step - loss: 0.4098 - mean_absolute_error: 0.4330\n",
      "Epoch 109/200\n",
      "20/20 [==============================] - 0s 56us/step - loss: 0.4099 - mean_absolute_error: 0.4336\n",
      "Epoch 110/200\n",
      "20/20 [==============================] - 0s 59us/step - loss: 0.4098 - mean_absolute_error: 0.4330\n",
      "Epoch 111/200\n",
      "20/20 [==============================] - 0s 87us/step - loss: 0.4099 - mean_absolute_error: 0.4339\n",
      "Epoch 112/200\n",
      "20/20 [==============================] - 0s 78us/step - loss: 0.4099 - mean_absolute_error: 0.4333\n",
      "Epoch 113/200\n",
      "20/20 [==============================] - 0s 100us/step - loss: 0.4099 - mean_absolute_error: 0.4340\n",
      "Epoch 114/200\n",
      "20/20 [==============================] - 0s 57us/step - loss: 0.4099 - mean_absolute_error: 0.4334\n",
      "Epoch 115/200\n",
      "20/20 [==============================] - 0s 85us/step - loss: 0.4099 - mean_absolute_error: 0.4342\n",
      "Epoch 116/200\n",
      "20/20 [==============================] - 0s 75us/step - loss: 0.4099 - mean_absolute_error: 0.4335\n",
      "Epoch 117/200\n",
      "20/20 [==============================] - 0s 118us/step - loss: 0.4099 - mean_absolute_error: 0.4340\n",
      "Epoch 118/200\n",
      "20/20 [==============================] - 0s 92us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 119/200\n",
      "20/20 [==============================] - 0s 79us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 120/200\n",
      "20/20 [==============================] - 0s 73us/step - loss: 0.4099 - mean_absolute_error: 0.4331\n",
      "Epoch 121/200\n",
      "20/20 [==============================] - 0s 94us/step - loss: 0.4099 - mean_absolute_error: 0.4336\n",
      "Epoch 122/200\n",
      "20/20 [==============================] - 0s 58us/step - loss: 0.4099 - mean_absolute_error: 0.4331\n",
      "Epoch 123/200\n",
      "20/20 [==============================] - 0s 88us/step - loss: 0.4099 - mean_absolute_error: 0.4339\n",
      "Epoch 124/200\n",
      "20/20 [==============================] - 0s 50us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 125/200\n",
      "20/20 [==============================] - 0s 73us/step - loss: 0.4099 - mean_absolute_error: 0.4337\n",
      "Epoch 126/200\n",
      "20/20 [==============================] - 0s 109us/step - loss: 0.4098 - mean_absolute_error: 0.4331\n",
      "Epoch 127/200\n",
      "20/20 [==============================] - 0s 115us/step - loss: 0.4099 - mean_absolute_error: 0.4339\n",
      "Epoch 128/200\n",
      "20/20 [==============================] - 0s 67us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 129/200\n",
      "20/20 [==============================] - 0s 61us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 130/200\n",
      "20/20 [==============================] - 0s 57us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 131/200\n",
      "20/20 [==============================] - 0s 57us/step - loss: 0.4099 - mean_absolute_error: 0.4340\n",
      "Epoch 132/200\n",
      "20/20 [==============================] - 0s 104us/step - loss: 0.4099 - mean_absolute_error: 0.4334\n",
      "Epoch 133/200\n",
      "20/20 [==============================] - 0s 107us/step - loss: 0.4099 - mean_absolute_error: 0.4340\n",
      "Epoch 134/200\n",
      "20/20 [==============================] - 0s 83us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 135/200\n",
      "20/20 [==============================] - 0s 84us/step - loss: 0.4099 - mean_absolute_error: 0.4339\n",
      "Epoch 136/200\n",
      "20/20 [==============================] - 0s 92us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 137/200\n",
      "20/20 [==============================] - 0s 52us/step - loss: 0.4099 - mean_absolute_error: 0.4337\n",
      "Epoch 138/200\n",
      "20/20 [==============================] - 0s 70us/step - loss: 0.4099 - mean_absolute_error: 0.4331\n",
      "Epoch 139/200\n",
      "20/20 [==============================] - 0s 43us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 140/200\n",
      "20/20 [==============================] - 0s 84us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 141/200\n",
      "20/20 [==============================] - 0s 121us/step - loss: 0.4099 - mean_absolute_error: 0.4336\n",
      "Epoch 142/200\n",
      "20/20 [==============================] - 0s 46us/step - loss: 0.4098 - mean_absolute_error: 0.4330\n",
      "Epoch 143/200\n",
      "20/20 [==============================] - 0s 73us/step - loss: 0.4098 - mean_absolute_error: 0.4336\n",
      "Epoch 144/200\n",
      "20/20 [==============================] - 0s 79us/step - loss: 0.4098 - mean_absolute_error: 0.4330\n",
      "Epoch 145/200\n",
      "20/20 [==============================] - 0s 81us/step - loss: 0.4099 - mean_absolute_error: 0.4339\n",
      "Epoch 146/200\n",
      "20/20 [==============================] - 0s 78us/step - loss: 0.4099 - mean_absolute_error: 0.4333\n",
      "Epoch 147/200\n",
      "20/20 [==============================] - 0s 85us/step - loss: 0.4099 - mean_absolute_error: 0.4339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/200\n",
      "20/20 [==============================] - 0s 49us/step - loss: 0.4099 - mean_absolute_error: 0.4333\n",
      "Epoch 149/200\n",
      "20/20 [==============================] - 0s 49us/step - loss: 0.4099 - mean_absolute_error: 0.4341\n",
      "Epoch 150/200\n",
      "20/20 [==============================] - 0s 50us/step - loss: 0.4099 - mean_absolute_error: 0.4333\n",
      "Epoch 151/200\n",
      "20/20 [==============================] - 0s 51us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 152/200\n",
      "20/20 [==============================] - 0s 54us/step - loss: 0.4098 - mean_absolute_error: 0.4331\n",
      "Epoch 153/200\n",
      "20/20 [==============================] - 0s 40us/step - loss: 0.4099 - mean_absolute_error: 0.4336\n",
      "Epoch 154/200\n",
      "20/20 [==============================] - 0s 51us/step - loss: 0.4098 - mean_absolute_error: 0.4331\n",
      "Epoch 155/200\n",
      "20/20 [==============================] - 0s 97us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 156/200\n",
      "20/20 [==============================] - 0s 82us/step - loss: 0.4099 - mean_absolute_error: 0.4331\n",
      "Epoch 157/200\n",
      "20/20 [==============================] - 0s 103us/step - loss: 0.4099 - mean_absolute_error: 0.4336\n",
      "Epoch 158/200\n",
      "20/20 [==============================] - 0s 74us/step - loss: 0.4098 - mean_absolute_error: 0.4330\n",
      "Epoch 159/200\n",
      "20/20 [==============================] - 0s 50us/step - loss: 0.4098 - mean_absolute_error: 0.4336\n",
      "Epoch 160/200\n",
      "20/20 [==============================] - 0s 61us/step - loss: 0.4098 - mean_absolute_error: 0.4331\n",
      "Epoch 161/200\n",
      "20/20 [==============================] - 0s 55us/step - loss: 0.4099 - mean_absolute_error: 0.4339\n",
      "Epoch 162/200\n",
      "20/20 [==============================] - 0s 66us/step - loss: 0.4099 - mean_absolute_error: 0.4333\n",
      "Epoch 163/200\n",
      "20/20 [==============================] - 0s 66us/step - loss: 0.4099 - mean_absolute_error: 0.4339\n",
      "Epoch 164/200\n",
      "20/20 [==============================] - 0s 69us/step - loss: 0.4098 - mean_absolute_error: 0.4332\n",
      "Epoch 165/200\n",
      "20/20 [==============================] - 0s 76us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 166/200\n",
      "20/20 [==============================] - 0s 87us/step - loss: 0.4098 - mean_absolute_error: 0.4331\n",
      "Epoch 167/200\n",
      "20/20 [==============================] - 0s 83us/step - loss: 0.4099 - mean_absolute_error: 0.4339\n",
      "Epoch 168/200\n",
      "20/20 [==============================] - 0s 51us/step - loss: 0.4099 - mean_absolute_error: 0.4332\n",
      "Epoch 169/200\n",
      "20/20 [==============================] - 0s 89us/step - loss: 0.4099 - mean_absolute_error: 0.4337\n",
      "Epoch 170/200\n",
      "20/20 [==============================] - 0s 69us/step - loss: 0.4098 - mean_absolute_error: 0.4331\n",
      "Epoch 171/200\n",
      "20/20 [==============================] - 0s 87us/step - loss: 0.4099 - mean_absolute_error: 0.4336\n",
      "Epoch 172/200\n",
      "20/20 [==============================] - 0s 80us/step - loss: 0.4098 - mean_absolute_error: 0.4330\n",
      "Epoch 173/200\n",
      "20/20 [==============================] - 0s 54us/step - loss: 0.4098 - mean_absolute_error: 0.4336\n",
      "Epoch 174/200\n",
      "20/20 [==============================] - 0s 77us/step - loss: 0.4098 - mean_absolute_error: 0.4330\n",
      "Epoch 175/200\n",
      "20/20 [==============================] - 0s 89us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 176/200\n",
      "20/20 [==============================] - 0s 71us/step - loss: 0.4098 - mean_absolute_error: 0.4332\n",
      "Epoch 177/200\n",
      "20/20 [==============================] - 0s 59us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 178/200\n",
      "20/20 [==============================] - 0s 116us/step - loss: 0.4098 - mean_absolute_error: 0.4331\n",
      "Epoch 179/200\n",
      "20/20 [==============================] - 0s 83us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 180/200\n",
      "20/20 [==============================] - 0s 68us/step - loss: 0.4098 - mean_absolute_error: 0.4332\n",
      "Epoch 181/200\n",
      "20/20 [==============================] - 0s 98us/step - loss: 0.4099 - mean_absolute_error: 0.4339\n",
      "Epoch 182/200\n",
      "20/20 [==============================] - 0s 91us/step - loss: 0.4098 - mean_absolute_error: 0.4332\n",
      "Epoch 183/200\n",
      "20/20 [==============================] - 0s 95us/step - loss: 0.4099 - mean_absolute_error: 0.4337\n",
      "Epoch 184/200\n",
      "20/20 [==============================] - 0s 57us/step - loss: 0.4098 - mean_absolute_error: 0.4330\n",
      "Epoch 185/200\n",
      "20/20 [==============================] - 0s 86us/step - loss: 0.4099 - mean_absolute_error: 0.4336\n",
      "Epoch 186/200\n",
      "20/20 [==============================] - 0s 59us/step - loss: 0.4098 - mean_absolute_error: 0.4331\n",
      "Epoch 187/200\n",
      "20/20 [==============================] - 0s 69us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 188/200\n",
      "20/20 [==============================] - 0s 138us/step - loss: 0.4098 - mean_absolute_error: 0.4331\n",
      "Epoch 189/200\n",
      "20/20 [==============================] - 0s 79us/step - loss: 0.4098 - mean_absolute_error: 0.4335\n",
      "Epoch 190/200\n",
      "20/20 [==============================] - 0s 87us/step - loss: 0.4098 - mean_absolute_error: 0.4329\n",
      "Epoch 191/200\n",
      "20/20 [==============================] - 0s 53us/step - loss: 0.4098 - mean_absolute_error: 0.4335\n",
      "Epoch 192/200\n",
      "20/20 [==============================] - 0s 68us/step - loss: 0.4098 - mean_absolute_error: 0.4330\n",
      "Epoch 193/200\n",
      "20/20 [==============================] - 0s 90us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 194/200\n",
      "20/20 [==============================] - 0s 88us/step - loss: 0.4098 - mean_absolute_error: 0.4332\n",
      "Epoch 195/200\n",
      "20/20 [==============================] - 0s 115us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 196/200\n",
      "20/20 [==============================] - 0s 93us/step - loss: 0.4098 - mean_absolute_error: 0.4332\n",
      "Epoch 197/200\n",
      "20/20 [==============================] - 0s 55us/step - loss: 0.4099 - mean_absolute_error: 0.4337\n",
      "Epoch 198/200\n",
      "20/20 [==============================] - 0s 58us/step - loss: 0.4098 - mean_absolute_error: 0.4331\n",
      "Epoch 199/200\n",
      "20/20 [==============================] - 0s 77us/step - loss: 0.4099 - mean_absolute_error: 0.4338\n",
      "Epoch 200/200\n",
      "20/20 [==============================] - 0s 97us/step - loss: 0.4098 - mean_absolute_error: 0.4331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x116051ba8>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(SMPC_returns, SMPC_returns, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_result = model.predict(SMPC_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.004094</td>\n",
       "      <td>1.011248</td>\n",
       "      <td>1.006418</td>\n",
       "      <td>1.010123</td>\n",
       "      <td>1.004725</td>\n",
       "      <td>1.021192</td>\n",
       "      <td>1.010779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019752</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.009324</td>\n",
       "      <td>1.004677</td>\n",
       "      <td>1.009370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.013669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.040217</td>\n",
       "      <td>1.072109</td>\n",
       "      <td>1.025811</td>\n",
       "      <td>1.007112</td>\n",
       "      <td>1.050598</td>\n",
       "      <td>1.071244</td>\n",
       "      <td>1.063067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.078311</td>\n",
       "      <td>...</td>\n",
       "      <td>1.043332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.064584</td>\n",
       "      <td>1.068087</td>\n",
       "      <td>1.047768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.047593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.034943</td>\n",
       "      <td>1.040119</td>\n",
       "      <td>1.043987</td>\n",
       "      <td>1.025521</td>\n",
       "      <td>1.043003</td>\n",
       "      <td>1.032150</td>\n",
       "      <td>1.032410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.065698</td>\n",
       "      <td>...</td>\n",
       "      <td>1.038409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.064199</td>\n",
       "      <td>1.046273</td>\n",
       "      <td>1.019809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.044797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988821</td>\n",
       "      <td>0.986226</td>\n",
       "      <td>1.020265</td>\n",
       "      <td>0.926185</td>\n",
       "      <td>1.021937</td>\n",
       "      <td>0.916128</td>\n",
       "      <td>0.954077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.068337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098628</td>\n",
       "      <td>1.036447</td>\n",
       "      <td>0.903802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966203</td>\n",
       "      <td>0.972070</td>\n",
       "      <td>0.971518</td>\n",
       "      <td>0.964766</td>\n",
       "      <td>0.970241</td>\n",
       "      <td>0.973204</td>\n",
       "      <td>0.968273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.982285</td>\n",
       "      <td>0.971732</td>\n",
       "      <td>0.961756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.019799</td>\n",
       "      <td>1.027166</td>\n",
       "      <td>1.025077</td>\n",
       "      <td>1.020146</td>\n",
       "      <td>1.023811</td>\n",
       "      <td>1.029837</td>\n",
       "      <td>1.024394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.042536</td>\n",
       "      <td>...</td>\n",
       "      <td>1.024498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.034784</td>\n",
       "      <td>1.024805</td>\n",
       "      <td>1.018267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.029859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.007958</td>\n",
       "      <td>1.048711</td>\n",
       "      <td>1.022877</td>\n",
       "      <td>1.022845</td>\n",
       "      <td>1.026859</td>\n",
       "      <td>1.044275</td>\n",
       "      <td>1.065557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.066210</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.030016</td>\n",
       "      <td>1.018394</td>\n",
       "      <td>1.050018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.029638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.023419</td>\n",
       "      <td>1.027579</td>\n",
       "      <td>1.035259</td>\n",
       "      <td>1.007285</td>\n",
       "      <td>1.034619</td>\n",
       "      <td>1.011758</td>\n",
       "      <td>1.016806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.060202</td>\n",
       "      <td>...</td>\n",
       "      <td>1.026111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.062751</td>\n",
       "      <td>1.039300</td>\n",
       "      <td>0.999486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.033157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.972626</td>\n",
       "      <td>0.979770</td>\n",
       "      <td>0.975531</td>\n",
       "      <td>0.977367</td>\n",
       "      <td>0.974014</td>\n",
       "      <td>0.987839</td>\n",
       "      <td>0.978959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.979716</td>\n",
       "      <td>0.974127</td>\n",
       "      <td>0.976577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.982038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.028533</td>\n",
       "      <td>1.032431</td>\n",
       "      <td>1.041290</td>\n",
       "      <td>1.010305</td>\n",
       "      <td>1.040744</td>\n",
       "      <td>1.014184</td>\n",
       "      <td>1.020674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.067384</td>\n",
       "      <td>...</td>\n",
       "      <td>1.031022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.071137</td>\n",
       "      <td>1.045876</td>\n",
       "      <td>1.001831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.038318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.968633</td>\n",
       "      <td>0.974984</td>\n",
       "      <td>0.972541</td>\n",
       "      <td>0.970532</td>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.980012</td>\n",
       "      <td>0.972721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.979659</td>\n",
       "      <td>0.971884</td>\n",
       "      <td>0.968568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.977867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.095491</td>\n",
       "      <td>1.096974</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>1.057099</td>\n",
       "      <td>1.117489</td>\n",
       "      <td>1.055431</td>\n",
       "      <td>1.075683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.154608</td>\n",
       "      <td>...</td>\n",
       "      <td>1.096095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.169830</td>\n",
       "      <td>1.126983</td>\n",
       "      <td>1.042084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.105895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.069821</td>\n",
       "      <td>1.077184</td>\n",
       "      <td>1.073081</td>\n",
       "      <td>1.074401</td>\n",
       "      <td>1.071367</td>\n",
       "      <td>1.085631</td>\n",
       "      <td>1.075833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.088228</td>\n",
       "      <td>...</td>\n",
       "      <td>1.074948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.078207</td>\n",
       "      <td>1.071707</td>\n",
       "      <td>1.073016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.080021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971945</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.975864</td>\n",
       "      <td>0.989370</td>\n",
       "      <td>0.976127</td>\n",
       "      <td>1.006701</td>\n",
       "      <td>1.003790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971547</td>\n",
       "      <td>0.970981</td>\n",
       "      <td>1.002445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.986092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983708</td>\n",
       "      <td>1.029776</td>\n",
       "      <td>0.995335</td>\n",
       "      <td>1.010347</td>\n",
       "      <td>0.999541</td>\n",
       "      <td>1.036169</td>\n",
       "      <td>1.053686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.036320</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990906</td>\n",
       "      <td>0.987813</td>\n",
       "      <td>1.044325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.006561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.007853</td>\n",
       "      <td>1.013312</td>\n",
       "      <td>1.015393</td>\n",
       "      <td>1.001657</td>\n",
       "      <td>1.014290</td>\n",
       "      <td>1.009024</td>\n",
       "      <td>1.007182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.035018</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.031795</td>\n",
       "      <td>1.016842</td>\n",
       "      <td>0.997036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.017453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.028772</td>\n",
       "      <td>1.036743</td>\n",
       "      <td>1.029218</td>\n",
       "      <td>1.039503</td>\n",
       "      <td>1.027261</td>\n",
       "      <td>1.052235</td>\n",
       "      <td>1.038366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.040560</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.027183</td>\n",
       "      <td>1.026246</td>\n",
       "      <td>1.040168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.038587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.009187</td>\n",
       "      <td>1.015404</td>\n",
       "      <td>1.014469</td>\n",
       "      <td>1.008319</td>\n",
       "      <td>1.013104</td>\n",
       "      <td>1.017326</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.031401</td>\n",
       "      <td>...</td>\n",
       "      <td>1.013465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.025018</td>\n",
       "      <td>1.014527</td>\n",
       "      <td>1.005375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.018805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.887462</td>\n",
       "      <td>0.895375</td>\n",
       "      <td>0.884709</td>\n",
       "      <td>0.904098</td>\n",
       "      <td>0.882662</td>\n",
       "      <td>0.917336</td>\n",
       "      <td>0.900185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.890733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.874829</td>\n",
       "      <td>0.880219</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.895936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.085809</td>\n",
       "      <td>1.087850</td>\n",
       "      <td>1.105547</td>\n",
       "      <td>1.051815</td>\n",
       "      <td>1.105689</td>\n",
       "      <td>1.051403</td>\n",
       "      <td>1.068622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.140610</td>\n",
       "      <td>...</td>\n",
       "      <td>1.086846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.153296</td>\n",
       "      <td>1.114238</td>\n",
       "      <td>1.038215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.096125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6         7   \\\n",
       "0   0.0  1.004094  1.011248  1.006418  1.010123  1.004725  1.021192  1.010779   \n",
       "1   0.0  1.040217  1.072109  1.025811  1.007112  1.050598  1.071244  1.063067   \n",
       "2   0.0  1.034943  1.040119  1.043987  1.025521  1.043003  1.032150  1.032410   \n",
       "3   0.0  0.988821  0.986226  1.020265  0.926185  1.021937  0.916128  0.954077   \n",
       "4   0.0  0.966203  0.972070  0.971518  0.964766  0.970241  0.973204  0.968273   \n",
       "5   0.0  1.019799  1.027166  1.025077  1.020146  1.023811  1.029837  1.024394   \n",
       "6   0.0  1.007958  1.048711  1.022877  1.022845  1.026859  1.044275  1.065557   \n",
       "7   0.0  1.023419  1.027579  1.035259  1.007285  1.034619  1.011758  1.016806   \n",
       "8   0.0  0.972626  0.979770  0.975531  0.977367  0.974014  0.987839  0.978959   \n",
       "9   0.0  1.028533  1.032431  1.041290  1.010305  1.040744  1.014184  1.020674   \n",
       "10  0.0  0.968633  0.974984  0.972541  0.970532  0.971098  0.980012  0.972721   \n",
       "11  0.0  1.095491  1.096974  1.117146  1.057099  1.117489  1.055431  1.075683   \n",
       "12  0.0  1.069821  1.077184  1.073081  1.074401  1.071367  1.085631  1.075833   \n",
       "13  0.0  0.971945  0.993548  0.975864  0.989370  0.976127  1.006701  1.003790   \n",
       "14  0.0  0.983708  1.029776  0.995335  1.010347  0.999541  1.036169  1.053686   \n",
       "15  0.0  1.007853  1.013312  1.015393  1.001657  1.014290  1.009024  1.007182   \n",
       "16  0.0  1.028772  1.036743  1.029218  1.039503  1.027261  1.052235  1.038366   \n",
       "17  0.0  1.009187  1.015404  1.014469  1.008319  1.013104  1.017326  1.011731   \n",
       "18  0.0  0.887462  0.895375  0.884709  0.904098  0.882662  0.917336  0.900185   \n",
       "19  0.0  1.085809  1.087850  1.105547  1.051815  1.105689  1.051403  1.068622   \n",
       "\n",
       "     8         9   ...        77   78        79        80        81   82  \\\n",
       "0   0.0  1.019752  ...  1.009093  0.0  1.009324  1.004677  1.009370  0.0   \n",
       "1   0.0  1.078311  ...  1.043332  0.0  1.064584  1.068087  1.047768  0.0   \n",
       "2   0.0  1.065698  ...  1.038409  0.0  1.064199  1.046273  1.019809  0.0   \n",
       "3   0.0  1.068337  ...  0.986350  0.0  1.098628  1.036447  0.903802  0.0   \n",
       "4   0.0  0.988038  ...  0.970233  0.0  0.982285  0.971732  0.961756  0.0   \n",
       "5   0.0  1.042536  ...  1.024498  0.0  1.034784  1.024805  1.018267  0.0   \n",
       "6   0.0  1.066210  ...  1.022575  0.0  1.030016  1.018394  1.050018  0.0   \n",
       "7   0.0  1.060202  ...  1.026111  0.0  1.062751  1.039300  0.999486  0.0   \n",
       "8   0.0  0.989401  ...  0.977448  0.0  0.979716  0.974127  0.976577  0.0   \n",
       "9   0.0  1.067384  ...  1.031022  0.0  1.071137  1.045876  1.001831  0.0   \n",
       "10  0.0  0.987401  ...  0.973033  0.0  0.979659  0.971884  0.968568  0.0   \n",
       "11  0.0  1.154608  ...  1.096095  0.0  1.169830  1.126983  1.042084  0.0   \n",
       "12  0.0  1.088228  ...  1.074948  0.0  1.078207  1.071707  1.073016  0.0   \n",
       "13  0.0  0.996770  ...  0.981524  0.0  0.971547  0.970981  1.002445  0.0   \n",
       "14  0.0  1.036320  ...  1.000495  0.0  0.990906  0.987813  1.044325  0.0   \n",
       "15  0.0  1.035018  ...  1.011550  0.0  1.031795  1.016842  0.997036  0.0   \n",
       "16  0.0  1.040560  ...  1.034385  0.0  1.027183  1.026246  1.040168  0.0   \n",
       "17  0.0  1.031401  ...  1.013465  0.0  1.025018  1.014527  1.005375  0.0   \n",
       "18  0.0  0.890733  ...  0.893099  0.0  0.874829  0.880219  0.907000  0.0   \n",
       "19  0.0  1.140610  ...  1.086846  0.0  1.153296  1.114238  1.038215  0.0   \n",
       "\n",
       "          83   84   85   86  \n",
       "0   1.013669  0.0  0.0  0.0  \n",
       "1   1.047593  0.0  0.0  0.0  \n",
       "2   1.044797  0.0  0.0  0.0  \n",
       "3   0.998186  0.0  0.0  0.0  \n",
       "4   0.975410  0.0  0.0  0.0  \n",
       "5   1.029859  0.0  0.0  0.0  \n",
       "6   1.029638  0.0  0.0  0.0  \n",
       "7   1.033157  0.0  0.0  0.0  \n",
       "8   0.982038  0.0  0.0  0.0  \n",
       "9   1.038318  0.0  0.0  0.0  \n",
       "10  0.977867  0.0  0.0  0.0  \n",
       "11  1.105895  0.0  0.0  0.0  \n",
       "12  1.080021  0.0  0.0  0.0  \n",
       "13  0.986092  0.0  0.0  0.0  \n",
       "14  1.006561  0.0  0.0  0.0  \n",
       "15  1.017453  0.0  0.0  0.0  \n",
       "16  1.038587  0.0  0.0  0.0  \n",
       "17  1.018805  0.0  0.0  0.0  \n",
       "18  0.895936  0.0  0.0  0.0  \n",
       "19  1.096125  0.0  0.0  0.0  \n",
       "\n",
       "[20 rows x 87 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(autoencoder_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAC</th>\n",
       "      <th>CHK</th>\n",
       "      <th>GE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>NOK</th>\n",
       "      <th>CSX</th>\n",
       "      <th>TEVA</th>\n",
       "      <th>ERIC</th>\n",
       "      <th>F</th>\n",
       "      <th>WFC</th>\n",
       "      <th>...</th>\n",
       "      <th>BX</th>\n",
       "      <th>GLW</th>\n",
       "      <th>SCHW</th>\n",
       "      <th>NUS</th>\n",
       "      <th>TXT</th>\n",
       "      <th>CX</th>\n",
       "      <th>OXY</th>\n",
       "      <th>CY</th>\n",
       "      <th>NEM</th>\n",
       "      <th>FLEX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-09-03</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.587225</td>\n",
       "      <td>0.983199</td>\n",
       "      <td>3.751059</td>\n",
       "      <td>4.961830</td>\n",
       "      <td>4.029734</td>\n",
       "      <td>0.057265</td>\n",
       "      <td>1.168210</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.632948</td>\n",
       "      <td>...</td>\n",
       "      <td>2.849832</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.807308</td>\n",
       "      <td>2.023463</td>\n",
       "      <td>1.987658</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.152059</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-04</th>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186269</td>\n",
       "      <td>10.578164</td>\n",
       "      <td>8.026349</td>\n",
       "      <td>6.218481</td>\n",
       "      <td>9.009944</td>\n",
       "      <td>7.392626</td>\n",
       "      <td>13.070701</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.701085</td>\n",
       "      <td>...</td>\n",
       "      <td>6.950920</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.395521</td>\n",
       "      <td>7.577531</td>\n",
       "      <td>10.444745</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.464132</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-05</th>\n",
       "      <td>100.0</td>\n",
       "      <td>4.241196</td>\n",
       "      <td>3.340355</td>\n",
       "      <td>2.296672</td>\n",
       "      <td>10.957160</td>\n",
       "      <td>4.788256</td>\n",
       "      <td>3.996287</td>\n",
       "      <td>5.751733</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.343793</td>\n",
       "      <td>...</td>\n",
       "      <td>5.800216</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.078564</td>\n",
       "      <td>5.449708</td>\n",
       "      <td>1.747273</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.936025</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-08</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.631887</td>\n",
       "      <td>5.479584</td>\n",
       "      <td>0.177534</td>\n",
       "      <td>3.982240</td>\n",
       "      <td>1.003539</td>\n",
       "      <td>6.939203</td>\n",
       "      <td>6.144355</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.679031</td>\n",
       "      <td>...</td>\n",
       "      <td>3.537388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.940302</td>\n",
       "      <td>0.485550</td>\n",
       "      <td>9.134086</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.214585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-09</th>\n",
       "      <td>100.0</td>\n",
       "      <td>6.135739</td>\n",
       "      <td>0.560103</td>\n",
       "      <td>2.202984</td>\n",
       "      <td>2.691731</td>\n",
       "      <td>5.067454</td>\n",
       "      <td>1.522788</td>\n",
       "      <td>1.379555</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.379698</td>\n",
       "      <td>...</td>\n",
       "      <td>1.683808</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.462849</td>\n",
       "      <td>0.969305</td>\n",
       "      <td>1.064522</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.031852</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-10</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.220421</td>\n",
       "      <td>2.826287</td>\n",
       "      <td>2.330381</td>\n",
       "      <td>0.335559</td>\n",
       "      <td>0.645193</td>\n",
       "      <td>3.229068</td>\n",
       "      <td>0.480651</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.510576</td>\n",
       "      <td>...</td>\n",
       "      <td>1.877779</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.173492</td>\n",
       "      <td>0.913151</td>\n",
       "      <td>0.092993</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.453796</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-11</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.770671</td>\n",
       "      <td>4.610434</td>\n",
       "      <td>3.541617</td>\n",
       "      <td>0.494675</td>\n",
       "      <td>7.210502</td>\n",
       "      <td>3.286330</td>\n",
       "      <td>6.759859</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.151098</td>\n",
       "      <td>...</td>\n",
       "      <td>3.282635</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.016571</td>\n",
       "      <td>2.079625</td>\n",
       "      <td>1.969199</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.963805</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-12</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.743764</td>\n",
       "      <td>8.174269</td>\n",
       "      <td>2.805769</td>\n",
       "      <td>0.533414</td>\n",
       "      <td>1.933649</td>\n",
       "      <td>1.393040</td>\n",
       "      <td>1.343366</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.659821</td>\n",
       "      <td>...</td>\n",
       "      <td>2.933655</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.624995</td>\n",
       "      <td>3.685417</td>\n",
       "      <td>0.410905</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.391457</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-15</th>\n",
       "      <td>100.0</td>\n",
       "      <td>7.123175</td>\n",
       "      <td>6.540079</td>\n",
       "      <td>8.287742</td>\n",
       "      <td>0.511092</td>\n",
       "      <td>2.632173</td>\n",
       "      <td>0.444732</td>\n",
       "      <td>1.970990</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.440508</td>\n",
       "      <td>...</td>\n",
       "      <td>5.406339</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.452804</td>\n",
       "      <td>0.479815</td>\n",
       "      <td>4.792827</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.170644</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-16</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.187518</td>\n",
       "      <td>1.347938</td>\n",
       "      <td>2.545250</td>\n",
       "      <td>0.456713</td>\n",
       "      <td>6.646119</td>\n",
       "      <td>1.065362</td>\n",
       "      <td>2.863980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.270799</td>\n",
       "      <td>...</td>\n",
       "      <td>2.293343</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.572927</td>\n",
       "      <td>0.830659</td>\n",
       "      <td>2.240889</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.634041</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-17</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.669056</td>\n",
       "      <td>4.459588</td>\n",
       "      <td>4.399337</td>\n",
       "      <td>1.693746</td>\n",
       "      <td>4.548845</td>\n",
       "      <td>0.741099</td>\n",
       "      <td>3.534683</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.170559</td>\n",
       "      <td>...</td>\n",
       "      <td>7.487745</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.577267</td>\n",
       "      <td>2.723327</td>\n",
       "      <td>7.136339</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.137051</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-18</th>\n",
       "      <td>100.0</td>\n",
       "      <td>5.544312</td>\n",
       "      <td>2.130541</td>\n",
       "      <td>3.283298</td>\n",
       "      <td>2.444280</td>\n",
       "      <td>4.622719</td>\n",
       "      <td>3.031267</td>\n",
       "      <td>2.970416</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.320440</td>\n",
       "      <td>...</td>\n",
       "      <td>3.399342</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.500957</td>\n",
       "      <td>11.267488</td>\n",
       "      <td>4.501164</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.627942</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-19</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.119159</td>\n",
       "      <td>0.313289</td>\n",
       "      <td>4.932290</td>\n",
       "      <td>0.904251</td>\n",
       "      <td>2.156053</td>\n",
       "      <td>7.926857</td>\n",
       "      <td>4.066126</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.166872</td>\n",
       "      <td>...</td>\n",
       "      <td>3.248438</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.056053</td>\n",
       "      <td>2.700093</td>\n",
       "      <td>4.395320</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.810520</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-22</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.808801</td>\n",
       "      <td>1.140497</td>\n",
       "      <td>5.995609</td>\n",
       "      <td>5.873050</td>\n",
       "      <td>2.953700</td>\n",
       "      <td>4.763247</td>\n",
       "      <td>1.353564</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.767003</td>\n",
       "      <td>...</td>\n",
       "      <td>7.097239</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.452799</td>\n",
       "      <td>3.070429</td>\n",
       "      <td>3.585983</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.288985</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-23</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.749388</td>\n",
       "      <td>7.930393</td>\n",
       "      <td>0.540905</td>\n",
       "      <td>1.747982</td>\n",
       "      <td>1.117484</td>\n",
       "      <td>2.827189</td>\n",
       "      <td>8.529709</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.695178</td>\n",
       "      <td>...</td>\n",
       "      <td>1.407537</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.619373</td>\n",
       "      <td>1.240583</td>\n",
       "      <td>7.015679</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.978528</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-24</th>\n",
       "      <td>100.0</td>\n",
       "      <td>4.116825</td>\n",
       "      <td>2.814671</td>\n",
       "      <td>2.787759</td>\n",
       "      <td>0.286817</td>\n",
       "      <td>4.025045</td>\n",
       "      <td>0.831547</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.199817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889728</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.868953</td>\n",
       "      <td>4.280442</td>\n",
       "      <td>4.022413</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.422213</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-25</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.841598</td>\n",
       "      <td>0.726196</td>\n",
       "      <td>3.965883</td>\n",
       "      <td>2.306865</td>\n",
       "      <td>0.871647</td>\n",
       "      <td>4.464032</td>\n",
       "      <td>0.415710</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.513477</td>\n",
       "      <td>...</td>\n",
       "      <td>4.809378</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.162731</td>\n",
       "      <td>1.391872</td>\n",
       "      <td>1.006778</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.218454</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-26</th>\n",
       "      <td>100.0</td>\n",
       "      <td>7.541966</td>\n",
       "      <td>3.269610</td>\n",
       "      <td>2.823112</td>\n",
       "      <td>3.701084</td>\n",
       "      <td>1.508040</td>\n",
       "      <td>1.047515</td>\n",
       "      <td>2.441439</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.678335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080424</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.659260</td>\n",
       "      <td>2.374984</td>\n",
       "      <td>3.724775</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.605062</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-29</th>\n",
       "      <td>100.0</td>\n",
       "      <td>3.078972</td>\n",
       "      <td>2.128980</td>\n",
       "      <td>6.412563</td>\n",
       "      <td>1.094560</td>\n",
       "      <td>8.235103</td>\n",
       "      <td>2.617701</td>\n",
       "      <td>1.737712</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.050359</td>\n",
       "      <td>...</td>\n",
       "      <td>4.375829</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.090005</td>\n",
       "      <td>10.126129</td>\n",
       "      <td>7.157898</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.588793</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-30</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.290109</td>\n",
       "      <td>1.453577</td>\n",
       "      <td>9.661031</td>\n",
       "      <td>0.740223</td>\n",
       "      <td>9.900230</td>\n",
       "      <td>0.439299</td>\n",
       "      <td>7.655471</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.053238</td>\n",
       "      <td>...</td>\n",
       "      <td>11.235209</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.611075</td>\n",
       "      <td>11.011649</td>\n",
       "      <td>2.490125</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.132862</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              BAC       CHK         GE       AMD        NOK       CSX  \\\n",
       "Date                                                                    \n",
       "2008-09-03  100.0  0.587225   0.983199  3.751059   4.961830  4.029734   \n",
       "2008-09-04  100.0  5.186269  10.578164  8.026349   6.218481  9.009944   \n",
       "2008-09-05  100.0  4.241196   3.340355  2.296672  10.957160  4.788256   \n",
       "2008-09-08  100.0  2.631887   5.479584  0.177534   3.982240  1.003539   \n",
       "2008-09-09  100.0  6.135739   0.560103  2.202984   2.691731  5.067454   \n",
       "2008-09-10  100.0  1.220421   2.826287  2.330381   0.335559  0.645193   \n",
       "2008-09-11  100.0  0.770671   4.610434  3.541617   0.494675  7.210502   \n",
       "2008-09-12  100.0  2.743764   8.174269  2.805769   0.533414  1.933649   \n",
       "2008-09-15  100.0  7.123175   6.540079  8.287742   0.511092  2.632173   \n",
       "2008-09-16  100.0  2.187518   1.347938  2.545250   0.456713  6.646119   \n",
       "2008-09-17  100.0  0.669056   4.459588  4.399337   1.693746  4.548845   \n",
       "2008-09-18  100.0  5.544312   2.130541  3.283298   2.444280  4.622719   \n",
       "2008-09-19  100.0  1.119159   0.313289  4.932290   0.904251  2.156053   \n",
       "2008-09-22  100.0  0.808801   1.140497  5.995609   5.873050  2.953700   \n",
       "2008-09-23  100.0  1.749388   7.930393  0.540905   1.747982  1.117484   \n",
       "2008-09-24  100.0  4.116825   2.814671  2.787759   0.286817  4.025045   \n",
       "2008-09-25  100.0  0.841598   0.726196  3.965883   2.306865  0.871647   \n",
       "2008-09-26  100.0  7.541966   3.269610  2.823112   3.701084  1.508040   \n",
       "2008-09-29  100.0  3.078972   2.128980  6.412563   1.094560  8.235103   \n",
       "2008-09-30  100.0  1.290109   1.453577  9.661031   0.740223  9.900230   \n",
       "\n",
       "                TEVA       ERIC      F        WFC  ...         BX    GLW  \\\n",
       "Date                                               ...                     \n",
       "2008-09-03  0.057265   1.168210  100.0   2.632948  ...   2.849832  100.0   \n",
       "2008-09-04  7.392626  13.070701  100.0  12.701085  ...   6.950920  100.0   \n",
       "2008-09-05  3.996287   5.751733  100.0   1.343793  ...   5.800216  100.0   \n",
       "2008-09-08  6.939203   6.144355  100.0   0.679031  ...   3.537388  100.0   \n",
       "2008-09-09  1.522788   1.379555  100.0   6.379698  ...   1.683808  100.0   \n",
       "2008-09-10  3.229068   0.480651  100.0   2.510576  ...   1.877779  100.0   \n",
       "2008-09-11  3.286330   6.759859  100.0   0.151098  ...   3.282635  100.0   \n",
       "2008-09-12  1.393040   1.343366  100.0   4.659821  ...   2.933655  100.0   \n",
       "2008-09-15  0.444732   1.970990  100.0   9.440508  ...   5.406339  100.0   \n",
       "2008-09-16  1.065362   2.863980  100.0   5.270799  ...   2.293343  100.0   \n",
       "2008-09-17  0.741099   3.534683  100.0   3.170559  ...   7.487745  100.0   \n",
       "2008-09-18  3.031267   2.970416  100.0   4.320440  ...   3.399342  100.0   \n",
       "2008-09-19  7.926857   4.066126  100.0   1.166872  ...   3.248438  100.0   \n",
       "2008-09-22  4.763247   1.353564  100.0  12.767003  ...   7.097239  100.0   \n",
       "2008-09-23  2.827189   8.529709  100.0   6.695178  ...   1.407537  100.0   \n",
       "2008-09-24  0.831547   0.018111  100.0   3.199817  ...   0.889728  100.0   \n",
       "2008-09-25  4.464032   0.415710  100.0   4.513477  ...   4.809378  100.0   \n",
       "2008-09-26  1.047515   2.441439  100.0   5.678335  ...   0.080424  100.0   \n",
       "2008-09-29  2.617701   1.737712  100.0   0.050359  ...   4.375829  100.0   \n",
       "2008-09-30  0.439299   7.655471  100.0   1.053238  ...  11.235209  100.0   \n",
       "\n",
       "                 SCHW        NUS        TXT     CX       OXY     CY    NEM  \\\n",
       "Date                                                                         \n",
       "2008-09-03   0.807308   2.023463   1.987658  100.0  1.152059  100.0  100.0   \n",
       "2008-09-04   9.395521   7.577531  10.444745  100.0  7.464132  100.0  100.0   \n",
       "2008-09-05   4.078564   5.449708   1.747273  100.0  4.936025  100.0  100.0   \n",
       "2008-09-08   4.940302   0.485550   9.134086  100.0  1.214585  100.0  100.0   \n",
       "2008-09-09   5.462849   0.969305   1.064522  100.0  6.031852  100.0  100.0   \n",
       "2008-09-10   2.173492   0.913151   0.092993  100.0  2.453796  100.0  100.0   \n",
       "2008-09-11   0.016571   2.079625   1.969199  100.0  2.963805  100.0  100.0   \n",
       "2008-09-12   8.624995   3.685417   0.410905  100.0  0.391457  100.0  100.0   \n",
       "2008-09-15   3.452804   0.479815   4.792827  100.0  5.170644  100.0  100.0   \n",
       "2008-09-16   4.572927   0.830659   2.240889  100.0  0.634041  100.0  100.0   \n",
       "2008-09-17   9.577267   2.723327   7.136339  100.0  1.137051  100.0  100.0   \n",
       "2008-09-18  11.500957  11.267488   4.501164  100.0  7.627942  100.0  100.0   \n",
       "2008-09-19   2.056053   2.700093   4.395320  100.0  4.810520  100.0  100.0   \n",
       "2008-09-22  10.452799   3.070429   3.585983  100.0  2.288985  100.0  100.0   \n",
       "2008-09-23   2.619373   1.240583   7.015679  100.0  5.978528  100.0  100.0   \n",
       "2008-09-24   3.868953   4.280442   4.022413  100.0  2.422213  100.0  100.0   \n",
       "2008-09-25   2.162731   1.391872   1.006778  100.0  2.218454  100.0  100.0   \n",
       "2008-09-26   0.659260   2.374984   3.724775  100.0  2.605062  100.0  100.0   \n",
       "2008-09-29   2.090005  10.126129   7.157898  100.0  6.588793  100.0  100.0   \n",
       "2008-09-30   3.611075  11.011649   2.490125  100.0  1.132862  100.0  100.0   \n",
       "\n",
       "             FLEX  \n",
       "Date               \n",
       "2008-09-03  100.0  \n",
       "2008-09-04  100.0  \n",
       "2008-09-05  100.0  \n",
       "2008-09-08  100.0  \n",
       "2008-09-09  100.0  \n",
       "2008-09-10  100.0  \n",
       "2008-09-11  100.0  \n",
       "2008-09-12  100.0  \n",
       "2008-09-15  100.0  \n",
       "2008-09-16  100.0  \n",
       "2008-09-17  100.0  \n",
       "2008-09-18  100.0  \n",
       "2008-09-19  100.0  \n",
       "2008-09-22  100.0  \n",
       "2008-09-23  100.0  \n",
       "2008-09-24  100.0  \n",
       "2008-09-25  100.0  \n",
       "2008-09-26  100.0  \n",
       "2008-09-29  100.0  \n",
       "2008-09-30  100.0  \n",
       "\n",
       "[20 rows x 87 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(abs(autoencoder_result - SMPC_returns)/SMPC_returns) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#input 87 stock data, and the hidden layer has 5 neurons; no biased involved (unless we let use_bias = TRUE)\n",
    "model.add(Dense(units = 3, input_dim = 10, activation='relu', kernel_initializer = 'he_normal', use_bias = False))\n",
    "model.add(Dense(units = 1, activation='relu', use_bias = False))\n",
    "\n",
    "model.predict(input_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = RMSprop(lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(input_stocks, normalized_SPY, epochs = 200, verbose = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Stock data from Yahoo Finance\n",
    "def download_stock_data(start_date, end_date, asset_list, filename):\n",
    "    \"\"\"\n",
    "    asset_list: list of asset to download\n",
    "    filename: name of the csv file where the data go to\n",
    "    \"\"\"\n",
    "    for i, asset in enumerate(asset_list):\n",
    "        if i == 0:\n",
    "            data = pdr.get_data_yahoo(asset_list[i], start_date,end_date)[['Adj Close']]\n",
    "            all_prices = data.rename(columns={\"Adj Close\": asset})\n",
    "            \n",
    "        else:\n",
    "            new_asset = pdr.get_data_yahoo(asset_list[i], start_date,end_date)[['Adj Close']]\n",
    "            all_prices = all_prices.join(new_asset.rename(columns={\"Adj Close\": asset}))\n",
    "    \n",
    "    all_prices.to_csv('./00_Data/' + filename + '.csv')\n",
    "    return\n",
    "\n",
    "# Extract Return and accumulated price data (starting value 1) from raw stock prices\n",
    "def process_stock_data(all_prices):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    all_prices: data frame, price of a list of stock from start date to the end date\n",
    "    \n",
    "    return:\n",
    "    all_price_norm: normalized asset price with the price on the first day as 1\n",
    "    all_returns: relative price\n",
    "    \"\"\"\n",
    "    n_time, n_assets = all_prices.shape\n",
    "    # Calculate returns\n",
    "    all_returns = all_prices.pct_change(1).apply(lambda a : a + 1)\n",
    "    \n",
    "    # Calculate relative price time series\n",
    "    all_prices_norm = all_returns.copy()\n",
    "    for i in range(n_time):\n",
    "        if i == 0:\n",
    "            all_prices_norm.iloc[0] = np.ones(n_assets)\n",
    "        else:\n",
    "            for j in range(n_assets):\n",
    "                if math.isnan(all_prices_norm.iloc[i,j]):\n",
    "                    all_prices_norm.iloc[i,j] = all_prices_norm.iloc[i-1,j]\n",
    "                else:\n",
    "                    all_prices_norm.iloc[i,j] = all_prices_norm.iloc[i,j] * all_prices_norm.iloc[i-1,j]\n",
    "                    \n",
    "    return all_prices_norm, all_returns.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1/fluc, 1, 1/fluc, 1, ...\n",
    "def teststock1(T, fluc):\n",
    "    stock = np.ones(T+1)\n",
    "    for i in range(T+1):\n",
    "        if i%2 == 1:\n",
    "            stock[i] = 1.0/fluc\n",
    "    return stock\n",
    "\n",
    "#Brownian Motion\n",
    "def teststock2(T, delta, sigma):\n",
    "    stock1 = np.zeros(T+1)\n",
    "    stock1[0] = 3.0\n",
    "    for i in range(T):\n",
    "        stock1[i+1] = stock1[i] + sigma + norm.rvs(scale=delta**2)\n",
    "        if (stock1[i+1] <= 0):\n",
    "            print('Negative Warning!')\n",
    "    return stock1\n",
    "\n",
    "#Garbage 1, 1/fluc, 1/pow(fluc,2) ,...\n",
    "def teststock3(T, discount):\n",
    "    stock = np.ones(T+1, dtype=float)\n",
    "    for i in range(T):\n",
    "        stock[i+1] = stock[i]*discount\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk Aware Portfolio Selection Algorithm\n",
    "#### Bug: cannot initialize gamma as cp.Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def Risk_Aware_Portfolio(stock_returns, gamma, delta):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    stock_return: returns for the stock data\n",
    "    gamma: the confidence level\n",
    "    delta: number of dates we use to estimate the density of returns\n",
    "    \n",
    "    output:\n",
    "    portfolio: portfolio selected\n",
    "    \"\"\"\n",
    "    u = cp.Variable((stock_returns.shape[1], 1))\n",
    "    a = cp.Variable()\n",
    "    #     gamma = cp.Parameter(gamma)\n",
    "\n",
    "    constraints = [cp.sum(u) == 1, u >= 0]\n",
    "\n",
    "    portfolio = []\n",
    "\n",
    "    for t in range(2, len(stock_returns)):\n",
    "        coefficient = 1 / ((delta + t - 1) * (1 - gamma))\n",
    "\n",
    "        sliced = stock_returns.iloc[:delta]\n",
    "        sliced = sliced.to_numpy()\n",
    "        inner_part = cp.pos(sliced * (-u) - a)\n",
    "        first_sum = cp.sum(inner_part)\n",
    "\n",
    "        sliced2 = stock_returns.iloc[:t - 1]\n",
    "        sliced2 = sliced2.to_numpy()\n",
    "        inner_part2 = sliced2 * (-u) - a\n",
    "        second_sum = cp.sum(cp.pos(inner_part2))\n",
    "\n",
    "        obj = cp.Minimize(a + coefficient * (first_sum + second_sum))\n",
    "\n",
    "        prob = cp.Problem(obj, constraints)\n",
    "        prob.solve(solver='SCS')\n",
    "        portfolio.append(u.value)\n",
    "\n",
    "    return portfolio\n",
    "\n",
    "    \"\"\"\n",
    "    n_time, n_assets = stock_returns.shape\n",
    "    portfolio = np.zeros((n_assets, n_time)) # the output portfolio\n",
    "    u = cp.Variable(n_assets) # portfolio vector\n",
    "    alpha = cp.Variable() # auxiliary variable\n",
    "    \n",
    "    constraints = [cp.sum(u) == 1, \n",
    "                u >= 0]\n",
    "    Gamma = cp.Parameter(nonneg = True,value = gamma)\n",
    "    \n",
    "    for t in range(delta + 1, n_time):\n",
    "        R = stock_returns.iloc[:t,:].dot(u).values\n",
    "        fct =  alpha + (cp.pos(-cp.sum(R[:delta])-alpha)+cp.pos(-cp.sum(R[:t-1])-alpha))/((delta + t - 1)*(1 - Gamma))\n",
    "        prob = cp.Problem(cp.Minimize(fct), constraints)\n",
    "        p = prob.solve()\n",
    "        portfolio[:,t] = u.value\n",
    "        \n",
    "    return portfolio\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(returns):\n",
    "    returns_temp = returns - np.mean(returns)\n",
    "    variance = np.sum(returns ** 2)/len(returns)\n",
    "    returns_temp /= variance\n",
    "    return returns_temp"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
